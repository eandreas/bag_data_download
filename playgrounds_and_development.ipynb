{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content of download.py - FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import filecmp\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URLs = {\n",
    "    'BAG_test_data': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/covid-19-basisdaten-labortests.xlsx.download.xlsx/Dashboard_3_COVID19_labtests_positivity.xlsx',\n",
    "    'BAG_report_data': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/covid-19-datengrundlage-lagebericht.xlsx.download.xlsx/200325_Datengrundlage_Grafiken_COVID-19-Bericht.xlsx',\n",
    "    'BAG_cases_data': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/covid-19-basisdaten-fallzahlen.xlsx.download.xlsx/Dashboards_1&2_COVID19_swiss_data_pv.xlsx',\n",
    "    'BAG_lab_findings': 'https://www.bag.admin.ch/dam/bag/en/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/covid-19-basisdaten-fallzahlen.csv.download.csv/Data%20on%20laboratory%20findings%20and%20deaths.csv',\n",
    "    'BAG_demographic_data': 'https://www.bag.admin.ch/dam/bag/en/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/covid-19-basisdaten-bevoelkerungszahlen.xlsx.download.xlsx/Population_Size_BFS.xlsx',\n",
    "    'BAG_covid19_website': 'https://www.covid19.admin.ch',\n",
    "    'BAG_2020_Q1': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/bisherige-lageberichte-q1-2020.zip.download.zip/Lageberichte_Quartal_1_2020_DE.zip',\n",
    "    'BAG_2020_Q2': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/bisherige-lageberichte-q2-2020.zip.download.zip/Lageberichte_Quartal_2_2020_DE.zip',\n",
    "    'BAG_2020_Q3': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/bisherige-lageberichte-q3-2020.zip.download.zip/Lageberichte_Quartal_3_2020_DE.zip',\n",
    "    'BAG_2020_Q4': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/bisherige-lageberichte-q4-2020.zip.download.zip/Lageberichte_Quartal_4_2020_DE.zip',\n",
    "    'BAG_2021_Q1': 'https://www.bag.admin.ch/dam/bag/de/dokumente/mt/k-und-i/aktuelle-ausbrueche-pandemien/2019-nCoV/bisherige-lageberichte-q1-2021.zip.download.zip/Bisherige%20Situationsberichte,%202021_Q1.zip',\n",
    "}\n",
    "\n",
    "def download(url, target_dir = Path.cwd(), file_name = None, overwrite = False):\n",
    "    '''\n",
    "    Downloads a file from an url into target_dir. If no file_name is probided, the file is named\n",
    "    as defined by the url. In case there is already a file named file_name within target_dir, overwrite=True\n",
    "    needs to be set to force saving the download.\n",
    "    '''\n",
    "    # get the file name from url if fn is None\n",
    "    if file_name is None:\n",
    "        file_name = url.split('/')[-1]\n",
    "    # exit if the file already exists and overwrite = False\n",
    "    f = target_dir / file_name\n",
    "    if (f.exists() and not overwrite):\n",
    "        return\n",
    "    # download and save the file\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(f, 'wb').write(r.content)\n",
    "    return f\n",
    "\n",
    "    \n",
    "def download_if_new(url, target_dir, suffix = ''):\n",
    "    '''\n",
    "    Downloads a file fro url and stores it in target_dir unless there is already a file with\n",
    "    the same content (byte-by-byte comparison).\n",
    "    '''\n",
    "    # get the last modified file\n",
    "    try:\n",
    "        time, latest = max((f.stat().st_mtime, f) for f in target_dir.glob('*' + suffix))\n",
    "    except ValueError as e:\n",
    "        latest = None\n",
    "    # download the current file from bag\n",
    "    f_download = download(url, target_dir, file_name = 'tmp', overwrite = True)\n",
    "    \n",
    "    # compare the latest file with the current download\n",
    "    if (latest is None):\n",
    "        same = False\n",
    "    else:\n",
    "        same = filecmp.cmp(str(latest), str(f_download), shallow = False)\n",
    "    \n",
    "    # rename or remove the current download if defferent from the previous file\n",
    "    if not same:\n",
    "        prefix = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        f_new = target_dir / (prefix + '_' + url.split('/')[-1])\n",
    "        f_download.replace(f_new)\n",
    "    else:\n",
    "        f_download.unlink()\n",
    "        \n",
    "def get_link_url(website, link_name, append_to_website = False):  \n",
    "    page = requests.get(website)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extract and store in top_items according to instructions on the left\n",
    "    links = soup.select('a')\n",
    "    url = None\n",
    "    for link in soup.select('a'):\n",
    "        text = link.text\n",
    "        text = text.strip() if text is not None else ''\n",
    "        if (text == link_name):\n",
    "            url = link.get('href')\n",
    "            url = url.strip() if url is not None else ''\n",
    "            break\n",
    "    \n",
    "    if (append_to_website):\n",
    "        url = website + url\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "# data directory definitions\n",
    "daily_reports_dir = Path('downloads/daily_reports')\n",
    "report_data_dir = Path('downloads/report_data')\n",
    "test_data_dir = Path('downloads/test_data')\n",
    "cases_data_dir = Path('downloads/cases_data')\n",
    "csv_data_dir = Path('downloads/csv_data')\n",
    "json_data_dir = Path('downloads/json_data')\n",
    "lab_findings_dir = Path('downloads/lab_findings')\n",
    "demographic_data_dir = Path('downloads/demographic_data')\n",
    "\n",
    "# create data directories\n",
    "Path.mkdir(daily_reports_dir, exist_ok = True)\n",
    "Path.mkdir(report_data_dir, exist_ok = True)\n",
    "Path.mkdir(test_data_dir, exist_ok = True)\n",
    "Path.mkdir(cases_data_dir, exist_ok = True)\n",
    "Path.mkdir(csv_data_dir, exist_ok = True)\n",
    "Path.mkdir(json_data_dir, exist_ok = True)\n",
    "Path.mkdir(lab_findings_dir, exist_ok = True)\n",
    "Path.mkdir(demographic_data_dir, exist_ok = True)\n",
    "\n",
    "# download new data\n",
    "download_if_new(URLs['BAG_2020_Q1'], daily_reports_dir, suffix = 'Quartal_1_2020_DE.zip')\n",
    "download_if_new(URLs['BAG_2020_Q2'], daily_reports_dir, suffix = 'Quartal_2_2020_DE.zip')\n",
    "download_if_new(URLs['BAG_2020_Q3'], daily_reports_dir, suffix = 'Quartal_3_2020_DE.zip')\n",
    "download_if_new(URLs['BAG_2020_Q4'], daily_reports_dir, suffix = 'Quartal_4_2020_DE.zip')\n",
    "download_if_new(URLs['BAG_2021_Q1'], daily_reports_dir, suffix = '202021_Q1.zip')\n",
    "#\n",
    "download_if_new(URLs['BAG_report_data'], report_data_dir, suffix = '.xlsx')\n",
    "download_if_new(URLs['BAG_test_data'], test_data_dir, suffix = '.xlsx')\n",
    "download_if_new(URLs['BAG_cases_data'], cases_data_dir, suffix = '.xlsx')\n",
    "download_if_new(URLs['BAG_lab_findings'], lab_findings_dir, suffix = '.csv')\n",
    "download_if_new(URLs['BAG_demographic_data'], demographic_data_dir, suffix = '.xlsx')\n",
    "#\n",
    "csv_url = get_link_url(URLs['BAG_covid19_website'], link_name = 'Daten als .csv', append_to_website = True)\n",
    "download_if_new(csv_url, csv_data_dir, suffix = '.zip')\n",
    "#\n",
    "json_url = get_link_url(URLs['BAG_covid19_website'], link_name = 'Daten als .json', append_to_website = True)\n",
    "download_if_new(json_url, json_data_dir, suffix = '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Make a request\n",
    "page = requests.get(\n",
    "    \"https://www.covid19.admin.ch/de/overview/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "bas_url = 'https://www.covid19.admin.ch'\n",
    "\n",
    "# Extract and store in top_items according to instructions on the left\n",
    "links = soup.select('a')\n",
    "\n",
    "for link in soup.select('a'):\n",
    "    text = link.text\n",
    "    text = text.strip() if text is not None else ''\n",
    "    if (text == 'Daten als .json'):\n",
    "        url = link.get('href')\n",
    "\n",
    "url = bas_url + url\n",
    "print(url)\n",
    "\n",
    "#download_if_new(url, Path.cwd(), suffix='.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcsv_data\u001b[m\u001b[m/                          \u001b[34mdownloads\u001b[m\u001b[m/\r\n",
      "download.py                        playgrounds_and_development.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid19",
   "language": "python",
   "name": "covid19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
